{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting Particle Markov Chain Monte Carlo\n",
    "## Introduction & Context\n",
    "\n",
    "This notebook presents the interacting particle markov chain monte carlo algorithm from http://proceedings.mlr.press/v48/rainforth16.html by Rainforth et al. (Proceedings of the 33rd International Conference on Machine Learning,). This algorithm is an extension of the family of particleMarkov chain Monte Carlo algorithms originally proposed in https://www.stats.ox.ac.uk/~doucet/andrieu_doucet_holenstein_PMCMC.pdf by Andrieu et al. .\n",
    "\n",
    "### Mathmatical context\n",
    "\n",
    "We will focus on a Markovian model even if the algorithm is not limited to this type of models.\n",
    "\n",
    "We have $x_t$ the states of our model and $y_t$ our observation following:\n",
    "- $ x_t | x_{1:t−1} ∼ f_t(x_t|x_{1:t−1}) $ the transition model \n",
    "- $ y_t | x_{1:t} ∼ g_t ( y_t | x_{1:t}) $ the observation model\n",
    "- $ x_1 ∼ \\mu(\\cdot)$\n",
    "\n",
    "Our goal is to compute expectation values with respect to the posterior distribution $ p(x_{1:T}|y_{1:T}) \\propto \\mu(x_1)\\prod\\limits_{t=2}^{T}f_t(x_t | x_{1:t-1}) \\prod\\limits_{t=1}^{T} g_t ( y_t | x_{1:t} ) $\n",
    "\n",
    "### Difficulties\n",
    "As explained in Andrieu et al., Sequential Monte Carlo (SMC) and Markov Chain Monte Carlo (MCMC) methods are often unreliable when the proposal distributions that are used to explore the space are poorly chosen and/or if highly correlated variables are updated independently. Particle Markov Chain Monte Carlo (PMCMC) try to solve theses issues using SMC methods to construct efficient proposals for the MCMC sampler. \n",
    "\n",
    "Interacting particle Markov Chain Monte Carlo tries to increase the efficiency of PMCMC, and solve its issue with *path degeneracy*.\n",
    "Whenever the ancestral lineage collapses at the early stages of the state sequence, the common ancestor is, by construction, guaranteed to be equal to the retained particle resulting in sample impoverishment, high correlation between the samples, and poor mixing of the Markov chain.\n",
    "\n",
    "To make things more concrete let's dive in the algorithm!\n",
    "\n",
    "## iPMCMC\n",
    "### Algorithm\n",
    "\n",
    "To explore the iPMCMC algorithm we must first explore SMC and CSMC, as iPMCMC uses both to generate efficient proposals of $x_{1:T}$ to the MCMC sampler.\n",
    "\n",
    "#### Sequential Monte Carlo\n",
    "\n",
    "The main idea of SMC is to generate at each time step a new position for each particle in our system, but instead of generating the next position of a particle with the particle past we take the past of any particle in our system with a discrete distribution based on the normalized weights of each one. \n",
    "The resulting particle system approximate $p(x_{1:t}|y_{1:t})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/algo1.PNG\" width=500px></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional Sequential Monte Carlo\n",
    "\n",
    "CSMC is basically the same as SMC but fixing one particle trajectory. All other particles can use this fixed past but the particle itself is fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/algo2.PNG\" width=500px></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interaction Particle Markov Chain Monte Carlo\n",
    "\n",
    "IPMCMC combines both previous algorithms as MCMC sampler.\n",
    "We have M workers, P of theses M workers being CSMC samplers and M-P SMC sampler.\n",
    "At each step $r$ of the sampler all the workers generate their output according to the previously explained protocols.\n",
    "Then for each CSMC worker we randomize its output between its own and any of the SMC workers, with probabilities:\n",
    "\n",
    "```Add equations here```\n",
    "\n",
    "We then choose the fixed trajectory of each CSMC worker with a weighted randomize choice over the new outputs outputs chosen previously.\n",
    "\n",
    "```Add equations here```\n",
    "\n",
    "The output of our algorithm is the chains of all CSMC workers chosen fixed particles. That gives us $R \\times P$ trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/algo3.PNG\" width=500px></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from tqdm import tqdm\n",
    "from ipmcmc.generate_data import *\n",
    "from ipmcmc.linear_gaussian_state_model import *\n",
    "from ipmcmc.non_linear_gaussian_state_model import *\n",
    "from ipmcmc.smc import *\n",
    "from ipmcmc.csmc import *\n",
    "from ipmcmc.ipmcmc import *\n",
    "from ipmcmc.estimation import *    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented the same models as those in the paper. Each one of them is implemented and generates observations and states in the two next cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1. Linear Gaussian State Space Model\n",
    "np.random.seed(420)\n",
    "# Parameters\n",
    "t_max = 50\n",
    "n_particles = 50\n",
    "\n",
    "r = R.from_rotvec(np.array([7*np.pi/10, 3*np.pi/10, np.pi/20]))\n",
    "rotation_matrix = r.as_dcm()\n",
    "scaling_matrix = 0.99*np.eye(3)\n",
    "beta = np.random.dirichlet(np.ones(20)*0.2, 3).transpose()\n",
    "alpha = scaling_matrix@rotation_matrix\n",
    "t_max = 50\n",
    "mu = np.array([0, 1, 1])\n",
    "start_var = 0.1*np.eye(3)\n",
    "omega = np.eye(3)\n",
    "sigma = 0.1*np.eye(20)\n",
    "\n",
    "\n",
    "\n",
    "l_transition_model = [LinearMu(default_mean=mu, default_cov=start_var)]+[LinearTransition(\n",
    "    default_mean=np.zeros(3), default_cov=omega, default_alpha=alpha) for t in range(1, t_max)]\n",
    "l_proposals = [LinearMu(default_mean=mu, default_cov=start_var)]+[LinearProposal(\n",
    "    default_mean=np.zeros(3), default_cov=omega, default_alpha=alpha) for t in range(1, t_max)]\n",
    "l_observation_model = [LinearObservation(default_mean=np.zeros(\n",
    "    20), default_cov=sigma, default_beta=beta) for t in range(0, t_max)]\n",
    "\n",
    "# If we want to change the parameters\n",
    "assert np.all(np.linalg.eigvals(start_var) > 0)\n",
    "assert np.all(np.linalg.eigvals(omega) > 0)\n",
    "assert np.all(np.linalg.eigvals(sigma) > 0)\n",
    "\n",
    "l_states, l_observations = linear_gaussian_state_space(\n",
    "    t_max=t_max, mu=mu, start_var=start_var, transition_var=omega, noise_var=sigma,\n",
    "    transition_coeffs=alpha, observation_coeffs=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2. Nonlinear State Space Model\n",
    "np.random.seed(420)\n",
    "nl_mu = 0\n",
    "start_std = np.sqrt(5)\n",
    "omega = np.sqrt(10)\n",
    "sigma = np.sqrt(10)\n",
    "\n",
    "nl_transition_model = [NonLinearMu(default_mean=nl_mu, default_std=start_std)]+[NonLinearTransition(\n",
    "    default_mean=0, default_std=omega) for t in range(1, t_max)]\n",
    "nl_proposals = [NonLinearMu(default_mean=nl_mu, default_std=start_std)]+[\n",
    "    NonLinearProposal(default_mean=0, default_std=omega) for t in range(1, t_max)]\n",
    "nl_observation_model = [NonLinearObservation(\n",
    "    default_mean=0, default_std=sigma) for t in range(0, t_max)]\n",
    "\n",
    "nl_states, nl_observations = nonlinear_gaussian_state_space(\n",
    "    t_max=t_max, mu=nl_mu, start_std=start_std, transition_std=omega, noise_std=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_conditional_traj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:21<00:00,  1.36s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ipmcmc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [08:05<00:00, 48.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# ipmcmc run: works with both linear and non-linear models.\n",
    "# It is pretty long to run, longer for the linear model which has 3-dimensional states.\n",
    "# For the linear model, each MCMC step take approximately 90 secs, and 80 secs for \n",
    "# the non-linear, on our computers.\n",
    "\n",
    "n_nodes = 32\n",
    "n_conditional_nodes = 16\n",
    "n_steps = 10\n",
    "\n",
    "linear= True\n",
    "\n",
    "if linear:\n",
    "    print('init_conditional_traj')\n",
    "    \n",
    "    init_conditional_traj = np.zeros((n_conditional_nodes, t_max, len(mu)))\n",
    "    for i in tqdm(range(n_conditional_nodes)):\n",
    "        \n",
    "        particles, weights, _ = smc(l_observations, n_particles,\n",
    "                              l_transition_model, l_proposals, l_observation_model)\n",
    "        b_j = np.argmax(weights[-1])\n",
    "        init_conditional_traj[i] = particles[:,b_j]\n",
    "\n",
    "    print('running ipmcmc')\n",
    "    particles, conditional_traj, weights, conditional_indices, zetas = ipmcmc(\n",
    "        n_steps, n_nodes, n_conditional_nodes, l_observations, n_particles, init_conditional_traj,\n",
    "        l_proposals, l_transition_model, l_observation_model)\n",
    "\n",
    "else:\n",
    "    print('init_conditional_traj')\n",
    "    \n",
    "    init_conditional_traj = np.zeros((n_conditional_nodes, t_max, 1))\n",
    "    for i in tqdm(range(n_conditional_nodes)):\n",
    "        particles, weights, _ = smc(nl_observations, n_particles,\n",
    "                              nl_transition_model, nl_proposals, nl_observation_model)\n",
    "        b_j = np.argmax(weights[-1])\n",
    "        init_conditional_traj[i] = particles[:,b_j]\n",
    "\n",
    "    print('running ipmcmc')\n",
    "    particles, conditional_traj, weights, conditional_indices, zetas = ipmcmc(\n",
    "        n_steps, n_nodes, n_conditional_nodes, nl_observations, n_particles, init_conditional_traj,\n",
    "        nl_proposals, nl_transition_model, nl_observation_model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean estimation for the linear model, using kalman filter and rts smoother as ground truth\n",
    "# Make sure that the particles used are the one generated during a run of the ipmcmc sampler\n",
    "# for the linear model\n",
    "\n",
    "true_means, true_covs = compute_ground_truth(l_observations, mu, start_var, alpha, omega, beta, sigma)\n",
    "\n",
    "rao_black_traj = rao_blackwellisation(particles, weights, zetas, n_conditional_nodes)\n",
    "\n",
    "errors_function_of_mcmc_step = []\n",
    "errors_function_of_state_step = []\n",
    "for r in range(1, (n_steps+1)):\n",
    "    errors_function_of_mcmc_step.append(compute_error(rao_black_traj, true_means, r))\n",
    "\n",
    "for t in range(1, (t_max+1)):\n",
    "    errors_function_of_state_step.append(compute_error(rao_black_traj, true_means, state_step=t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3688515928237122,\n",
       " 0.2761470221866041,\n",
       " 0.21321855403115264,\n",
       " 0.17755261369705375,\n",
       " 0.15314406304965547,\n",
       " 0.16648230949920395,\n",
       " 0.205608010381481,\n",
       " 0.19228652075904637,\n",
       " 0.21119470063050608,\n",
       " 0.3154178824612124,\n",
       " 0.4155884215376102,\n",
       " 0.5149025844876897,\n",
       " 0.6618559931133046,\n",
       " 0.7890790115156365,\n",
       " 0.9358789937910965,\n",
       " 0.9457981276261777,\n",
       " 0.984141844712793,\n",
       " 1.074747845951816,\n",
       " 1.2190781328401392,\n",
       " 1.2508610237480597,\n",
       " 1.2260258751211353,\n",
       " 1.2745099324455424,\n",
       " 1.385018915016812,\n",
       " 1.3871075653920328,\n",
       " 1.4276801983246685,\n",
       " 1.451826024096275,\n",
       " 1.4181119495277565,\n",
       " 1.3725338052073133,\n",
       " 1.3345709316081888,\n",
       " 1.3397113172359763,\n",
       " 1.3365120746450334,\n",
       " 1.3246750908892764,\n",
       " 1.3062443835907427,\n",
       " 1.2902223716917873,\n",
       " 1.271303310774959,\n",
       " 1.2444057104296562,\n",
       " 1.210968773267793,\n",
       " 1.1961398208104794,\n",
       " 1.1752438837024544,\n",
       " 1.152876525739712,\n",
       " 1.1382160647483335,\n",
       " 1.1381254831729082,\n",
       " 1.1148603880461474,\n",
       " 1.0903109413607983,\n",
       " 1.0675169949319205,\n",
       " 1.0563250336625247,\n",
       " 1.0419343336324292,\n",
       " 1.027062951995083,\n",
       " 1.0194207132360753,\n",
       " 1.0028214780473097]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_function_of_state_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
